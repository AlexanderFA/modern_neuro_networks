{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "class DynamicFcNN(nn.Module):\n",
    "    def __init__(self, layers_count=3, activation_func=torch.relu):\n",
    "        super(DynamicFcNN, self).__init__()\n",
    "        if layers_count <= 0:\n",
    "            raise Exception(\"layers_count must be greater than 0\")\n",
    "        self.activation_func, self.layers_count, self.flatten = activation_func, layers_count, nn.Flatten()\n",
    "        in_size, layer_sizes = 28 * 28, []\n",
    "        fc_i = 0\n",
    "        while layers_count > 0:\n",
    "            fc_i += 1\n",
    "            layers_count -= 1\n",
    "            out_size = 128 * (2 ** layers_count)\n",
    "            setattr(self, f'fc{fc_i}', nn.Linear(in_size, out_size))\n",
    "            layer_sizes.append([in_size, out_size])\n",
    "            in_size = out_size\n",
    "        self.fc_last = nn.Linear(out_size, 10)  # Выходной слой с 10 нейронами\n",
    "        print('Создана модель с функцией активации %s, Слои: %s' % (activation_func.__name__, layer_sizes + [[out_size, 10]]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        fc_i = 0\n",
    "        while fc_i < self.layers_count:\n",
    "            fc_i += 1\n",
    "            layer = getattr(self, f'fc{fc_i}')\n",
    "            x = self.activation_func(layer(x))\n",
    "        return self.fc_last(x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Количество слоев {self.layers_count}, Функция активации: '{self.activation_func.__name__}'\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "def fc_learn(fc_model, step_size=0.1, num_epochs=5):\n",
    "    print(f\"Обучаем модель: {fc_model}\")\n",
    "    fc_criterion, fc_epoch_losses = nn.CrossEntropyLoss(), []\n",
    "    fc_optimizer = optim.SGD(fc_model.parameters(), lr=step_size)\n",
    "    fc_total_step = len(train_loader)\n",
    "    fc_loss_list, fc_acc_list = [], []\n",
    "    for fc_epoch in range(num_epochs): # num epochs\n",
    "        fc_model.train()  # Установка модели в режим обучения\n",
    "        fc_running_loss = 0.0\n",
    "        for fc_i, (fc_images, fc_labels) in enumerate(train_loader):\n",
    "            fc_optimizer.zero_grad()  # Обнуление градиентов\n",
    "            fc_outputs = fc_model(fc_images)  # Получение выхода модели\n",
    "            fc_loss = fc_criterion(fc_outputs, fc_labels)  # Вычисление потерь\n",
    "            fc_loss.backward()  # Обратное распространение ошибки\n",
    "            fc_optimizer.step()  # Обновление весов\n",
    "            fc_running_loss += fc_loss.item() * fc_images.size(0)  # Учитываем потери по всем изображениям\n",
    "\n",
    "            # Отслеживание точности\n",
    "            fc_total = fc_labels.size(0)\n",
    "            _, fc_predicted = torch.max(fc_outputs.data, 1)\n",
    "            fc_correct = (fc_predicted == fc_labels).sum().item()\n",
    "            fc_acc_list.append(fc_correct / fc_total)\n",
    "\n",
    "            if (fc_i + 1) % 300 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                    .format(fc_epoch + 1, num_epochs, fc_i + 1, fc_total_step, fc_loss.item(), (fc_correct / fc_total) * 100))\n",
    "\n",
    "        fc_epoch_losses.append(fc_running_loss / len(train_loader.dataset))  # Вычисляем среднюю потерю за эпоху\n",
    "    print(f\"Потери по эпохам:\", fc_epoch_losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создана модель с функцией активации relu, Слои: [[784, 256], [256, 128], [128, 10]]\n",
      "Обучаем модель: Количество слоев 2, Функция активации: 'relu'\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4290, Accuracy: 89.00%\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2742, Accuracy: 91.00%\n",
      "Потери по эпохам: [0.44562239915132523]\n",
      "Время обучения FC модели: 24.92 секунд\n"
     ]
    }
   ],
   "source": [
    "fc_model = DynamicFcNN(layers_count=2, activation_func=torch.relu)\n",
    "start_time = time.time()\n",
    "fc_learn(fc_model, step_size=0.05, num_epochs=1)\n",
    "end_time = time.time()\n",
    "print(\"Время обучения FC модели: {:.2f} секунд\".format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, layers_count=3, activation_func=nn.ReLU()):\n",
    "        super(ConvNet, self).__init__()\n",
    "        if layers_count <= 0:\n",
    "            raise Exception(\"layers_count must be greater than 0\")\n",
    "        self.layers_count, self.drop_out = layers_count, nn.Dropout()\n",
    "        in_size, out_size = 1, 32\n",
    "        idx = 0\n",
    "        current_features = 700\n",
    "        while idx < self.layers_count:\n",
    "            idx += 1\n",
    "            layer = nn.Sequential(nn.Conv2d(in_size, out_size, kernel_size=5, stride=1, padding=2), activation_func, nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            in_size, out_size = out_size, out_size * 2\n",
    "            setattr(self, f'layer{idx}', layer)\n",
    "            if idx == 1:\n",
    "                downsampling = 2\n",
    "                side = int(28 / 2 / downsampling / 2 ** (layers_count - 2))\n",
    "                if side == 0:\n",
    "                    side = 1\n",
    "                in_feaures = side * side * 64 * 2 ** (layers_count - 2)\n",
    "                # print([in_feaures, current_features])\n",
    "                layer_function = nn.Linear(in_feaures, current_features)\n",
    "            elif idx == layers_count:\n",
    "                # print(current_features)\n",
    "                layer_function = nn.Linear(current_features, 10)\n",
    "            else:\n",
    "                prev_layer = getattr(self, f'fc{idx - 1}')\n",
    "                if idx < (self.layers_count // 2):\n",
    "                    current_features *= 2\n",
    "                else:\n",
    "                    current_features //= 2\n",
    "                # print([prev_layer.out_features, current_features])\n",
    "                layer_function = nn.Linear(prev_layer.out_features, current_features)\n",
    "            setattr(self, f'fc{idx}', layer_function)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        idx = 0\n",
    "        while idx < self.layers_count:\n",
    "            idx += 1\n",
    "            layer = getattr(self, f'layer{idx}')\n",
    "            out = layer(out)\n",
    "            # print(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        idx = 0\n",
    "        while idx < self.layers_count:\n",
    "            idx += 1\n",
    "            fc = getattr(self, f'fc{idx}')\n",
    "            out = fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [300/600], Loss: 0.0799, Accuracy: 99.00%\n",
      "Epoch [1/1], Step [600/600], Loss: 0.1456, Accuracy: 94.00%\n",
      "Потери по эпохам: [0.25180290155112744]\n",
      "Время обучения Conv модели: 61.32 секунд\n"
     ]
    }
   ],
   "source": [
    "conv_num_epochs = 1\n",
    "conv_criterion = nn.CrossEntropyLoss()\n",
    "conv_model = ConvNet(layers_count=2)\n",
    "# conv_optimizer = torch.optim.Adam(conv_model.parameters(), lr=0.01)\n",
    "conv_optimizer = optim.SGD(params=conv_model.parameters(), lr=0.05)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list, acc_list, conv_epoch_losses = [], [], []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(conv_num_epochs):\n",
    "    conv_running_loss = 0.0\n",
    "    conv_model.train()\n",
    "    for i, (conv_images, conv_labels) in enumerate(train_loader):\n",
    "        # Прямой запуск\n",
    "        outputs = conv_model(conv_images)\n",
    "        conv_loss = conv_criterion(outputs, conv_labels)\n",
    "        loss_list.append(conv_loss.item())\n",
    "\n",
    "        # Обратное распространение и оптимизатор\n",
    "        conv_optimizer.zero_grad()\n",
    "        conv_loss.backward()\n",
    "        conv_optimizer.step()\n",
    "        conv_running_loss += conv_loss.item() * conv_images.size(0)  # Учитываем потери по всем изображениям\n",
    "\n",
    "        # Отслеживание точности\n",
    "        total = conv_labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == conv_labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 300 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                .format(epoch + 1, conv_num_epochs, i + 1, total_step, conv_loss.item(), (correct / total) * 100))\n",
    "\n",
    "    conv_epoch_losses.append(conv_running_loss / len(train_loader.dataset))  # Вычисляем среднюю потерю за эпоху\n",
    "end_time = time.time()\n",
    "print(f\"Потери по эпохам:\", conv_epoch_losses)\n",
    "print(\"Время обучения Conv модели: {:.2f} секунд\".format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "def assessment(model):\n",
    "    model.eval()\n",
    "    as_total, as_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for as_images, as_labels in test_loader:\n",
    "            as_outputs = model(as_images)\n",
    "            _, as_predicted = torch.max(as_outputs.data, 1)\n",
    "            as_total += as_labels.size(0)\n",
    "            as_correct += (as_predicted == as_labels).sum().item()\n",
    "\n",
    "        as_accuracy = 100 * as_correct / as_total\n",
    "    return as_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность FC модели при проверке на тестовом наборе: 93.60%\n",
      "Точность Conv модели при проверке на тестовом наборе: 97.32%\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность FC модели при проверке на тестовом наборе: {assessment(fc_model):.2f}%')\n",
    "print(f'Точность Conv модели при проверке на тестовом наборе: {assessment(conv_model):.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # torch.save(conv_model.state_dict(), 'conv_net_model.ckpt')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
